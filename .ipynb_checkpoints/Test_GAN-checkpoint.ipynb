{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Generator(torch.nn.Module):\\n\\n    def __init__(self):\\n        super().__init__()\\n        self.l_one = torch.nn.Linear(INPUT, HIDDEN_1)\\n        self.l_two = torch.nn.Linear(HIDDEN_1, HIDDEN_2)\\n        self.l_three = torch.nn.Linear(HIDDEN_2, OUT)\\n        \\n    def forward(self, x):\\n        x = F.relu(self.l_one(x))\\n        x = F.relu(self.l_two(x))\\n        x = F.relu(self.l_three(x))\\n        return x.view(-1, 28, 28)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT, OUT = 28**2, 28**2\n",
    "HIDDEN_1, HIDDEN_2 = int(0.8*INPUT), int(0.8*INPUT)\n",
    "CLASSES = 2\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    '''\n",
    "     Network to discriminate between real and fake images.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l_one = torch.nn.Conv2d(1, 8, kernel_size=12, stride=1)\n",
    "        self.l_two = torch.nn.Conv2d(8, 16, kernel_size=12, stride=1)\n",
    "        self.l_three = torch.nn.Conv2d(16, 2, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.l_one(x))\n",
    "        x = F.relu(self.l_two(x))\n",
    "        n, c, h, w = x.size()\n",
    "        x = F.avg_pool2d(x, kernel_size=[h, w])\n",
    "        x = self.l_three(x).view(-1, CLASSES)\n",
    "        return x\n",
    "    \n",
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l_one = torch.nn.Conv2d(1, 3, kernel_size=4, stride=1, padding=2) \n",
    "        self.l_two = torch.nn.Conv2d(3, 12, kernel_size=8, stride=1, padding=4) \n",
    "        self.l_three = torch.nn.Conv2d(12, 24, kernel_size=4, stride=1, padding=2) \n",
    "        self.l_four = torch.nn.Conv2d(24, 1, kernel_size=4, stride=1, padding=2) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(28, 28).unsqueeze(0).unsqueeze(1)\n",
    "        x = F.relu(self.l_one(x))\n",
    "        print(x.data.shape)\n",
    "        x = F.relu(self.l_two(x))\n",
    "        print(x.data.shape)\n",
    "        x = F.relu(self.l_three(x))\n",
    "        print(x.data.shape)\n",
    "        x = F.relu(self.l_four(x))\n",
    "        print(x.data.shape)\n",
    "        x = x.view(-1, 28, 28)\n",
    "        return x.squeeze()\n",
    "'''\n",
    "class Generator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l_one = torch.nn.Linear(INPUT, HIDDEN_1)\n",
    "        self.l_two = torch.nn.Linear(HIDDEN_1, HIDDEN_2)\n",
    "        self.l_three = torch.nn.Linear(HIDDEN_2, OUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l_one(x))\n",
    "        x = F.relu(self.l_two(x))\n",
    "        x = F.relu(self.l_three(x))\n",
    "        return x.view(-1, 28, 28)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('minst_test_images.npy')\n",
    "N = len(images)\n",
    "images = (images.reshape((N, 28, 28)) / 255).astype(np.float_) # reshape data to 28 x 28 image and normalize\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc(batch_size):\n",
    "    # train Discriminator on real data\n",
    "    dis_model.zero_grad()\n",
    "    perm = np.random.choice(N, size=batch_size, replace=False)\n",
    "    real_data = Variable(torch.Tensor(images[perm]))\n",
    "    real_out = dis_model(real_data)\n",
    "    real_error = loss(real_out, Variable(torch.LongTensor(np.ones(batch_size))))\n",
    "    real_error.backward()\n",
    "    # train Discriminator on generated data\n",
    "    input_ = Variable(torch.Tensor(np.random.randn(batch_size, INPUT)))\n",
    "    fake_data = gen_model(input_).detach()\n",
    "    fake_out = dis_model(fake_data)\n",
    "    fake_error = loss(fake_out, Variable(torch.LongTensor(np.zeros(batch_size))))\n",
    "    fake_error.backward()\n",
    "    dis_optim.step()\n",
    "    return real_error.data[0], fake_error.data[0]\n",
    "\n",
    "def train_gen(batch_size):\n",
    "    gen_model.zero_grad()\n",
    "    input_ = Variable(torch.Tensor(np.random.randn(batch_size, INPUT)))\n",
    "    gen_data = gen_model(input_)\n",
    "    gen_out = dis_model(gen_data)\n",
    "    gen_error = loss(gen_out, Variable(torch.LongTensor(np.ones(batch_size))))\n",
    "    gen_error.backward()\n",
    "    gen_optim.step()\n",
    "    return gen_error.data[0]\n",
    "\n",
    "def get_dis_class():\n",
    "    dis_model.eval()\n",
    "    perm = np.random.choice(N, size=100, replace=False)\n",
    "    data = Variable(torch.Tensor(images[perm]))\n",
    "    max_, out = torch.max(dis_model(data), dim=1)\n",
    "    return (out.data.numpy() == np.ones(100)).astype(float).mean()\n",
    "\n",
    "def get_gen_class():\n",
    "    gen_model.eval()\n",
    "    dis_model.eval()\n",
    "    input_ = Variable(torch.Tensor(np.random.randn(100, INPUT)))\n",
    "    fake_data = gen_model(input_)\n",
    "    max_, out = torch.max(dis_model(fake_data), dim=1)\n",
    "    return (out.data.numpy() == np.ones(100)).astype(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "gen_model = Generator()\n",
    "dis_model = Discriminator()\n",
    "gen_optim = torch.optim.Adam(gen_model.parameters(), lr)\n",
    "dis_optim = torch.optim.Adam(dis_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: size '[-1 x 28 x 28]' is invalid for input with 1024 elements at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/TH/THStorage.c:37",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f9e97387936f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4ae14030c175>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_three\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_four\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m '''\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: size '[-1 x 28 x 28]' is invalid for input with 1024 elements at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/TH/THStorage.c:37"
     ]
    }
   ],
   "source": [
    "ITERS, BATCH_SIZE = 30000, 100\n",
    "for i in range(ITERS):\n",
    "    if i % 1000 == 0:\n",
    "        print('Iteration %d' % (i))\n",
    "        input_ = Variable(torch.Tensor(np.random.randn(INPUT)))\n",
    "        img = gen_model(input_).data.numpy()[0]\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    train_disc(BATCH_SIZE)\n",
    "    train_gen(BATCH_SIZE)\n",
    "print('TESTING')\n",
    "input_ = Variable(torch.Tensor(np.random.randn(INPUT)))\n",
    "img = gen_model(input_).data.numpy()[0]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
